---
title: "Accelerate your Python code with Cython"
date: 2019-06-17
categories:
  - Cython
---

Python is known to be slow because it is a script language. 
So, I always ask a question to the interviewers who claim to be familiar with Python: Will Python be significantly faster if we compile Python scripts into native codes beforehand? 
The answer is definitively *NO*!
Then, what the hell makes Python run slowly?. 
Please be patient, I will reveal the answer in the following paragraphs.

Let us start with some confusing terms: Python, CPython, and Cython. 
CPython is acctually the most widely used Python implementation. 
When you download a Python interpreter from its homepage, you are downloading a CPython.
CPython compiles your Python code into bytecode and interprets them in an evaluation loop.
That is why we call Python as a script language.

Cython does something more than CPython. 
It maps Python scripts into c codes and compiles them into native codes directly.
The following shows the compilation process of Cython, where the .pyx extension is Cython's version of .py.

```
demo.pyx -> demo.c -> demo.o
```

Here is an example.
We have a simple Python script called demo.py as below.

```python
# demo.py
def demo():
  a = 1
  b = 2
  c = a + b
  return c
```

Then, we compile the script into the c code. The following is a snapshot of the generated code. 
```c
// demo.c
// ...

PyObject *__pyx_v_a = NULL;
PyObject *__pyx_v_b = NULL;
PyObject *__pyx_v_c = NULL;
PyObject *__pyx_r = NULL;

// python code: a = 1
__Pyx_INCREF(__pyx_int_1);
__pyx_v_a = __pyx_int_1;

// python code: b = 2
__Pyx_INCREF(__pyx_int_2);
  __pyx_v_b = __pyx_int_2;

// python code: c = a + b
__pyx_t_1 = PyNumber_Add(__pyx_v_a, __pyx_v_b); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 4, __pyx_L1_error)
__Pyx_GOTREF(__pyx_t_1);
__pyx_v_c = __pyx_t_1;
__pyx_t_1 = 0;

// python code: return c
__Pyx_XDECREF(__pyx_r);
__Pyx_INCREF(__pyx_v_c);
__pyx_r = __pyx_v_c;
goto __pyx_L0;
// ...
```

It is easy to find that Python has done lots of extra things event for a simple plus operator.
From the code, we can find some clues about Python's mechanism.

 - PyObject is used to wrap all of the Pythyon classes, even for primary objects like int.
 - __Pyx_INCREF is used to maintain the reference count of an object, which will further be used for garbage collection. 
 - PyNumber_Add is called for adding instead of the standard '+' operator. So that Python supports high precisoin operations on integers. 

Now, we can draw the conclusion that Python is slow because of its rich features. 
It has done too much for the programmers to make programming a easy job, with the sacriface of performance.
It is a worthy tradeoff because performance is not very important in our daily life, our CPU is so powerful that a decress on the efficiency does not seem to be a problem. 
Unfortunately, it is not always the truth.
Imaging that we want to operate on a large of numbers. 
For example, calculate the sum of 10 million integers. Let us see what will hapen.

```python
import time
import numpy as np

def demo(data: np.ndarray):
    sum = 0
    for d in data:
        sum += d
    return sum

ts = time.time()
data = np.random.randint(-10000, 10000, 10000000)
demo(data)
print('sum causes %fs' % (time.time() - ts))

#########################
#
# sum causes 6.736042s
#
```

Although 6 seconds is not much, but it has spent much more than it actually needs. Let us speed it up.
We will continue to use Cython to perform the optimization. 

The first step is quite easy. We simply change `def` to `cdef` in the python code. And the function looks as below.
```python
cdef demo(data: np.ndarray):
    sum = 0
    for d in data:
        sum += d
    return sum

#########################
#
# sum causes 3.715279s
#
```
Amazing! We managed to recude the latency by a half without much efforts.
But it only simplifies the definition of the function, the loop operation is as slow as before.
Now, we want to get rid of the annoying PyObject because we know both `sum` and `data` can be interpreted as pure c integer and integer array, respectively.
And we have the second version.

```python
cdef long demo(long[::1] data):
    cdef long sum = 0
    cdef int i
    for i in range(len(data)):
        sum += data[i]
    return sum

#########################
#
# sum causes 1.802022s
#
```

By writing the code in a c-styled way, we managed to accelerate the sum operation further.
Now, the compiler knows that `sum` is a long value. No PyObject is used here. 
Notice the `[::1]` annotation for `data`, it represents memoryview, which is a class represting Python's view of the underlaying c arrays.
The next step is to get rid of the memoryview.

```python
cdef long demo(long* data, int length):
    cdef long sum = 0
    for i in range(length):
        sum += data[i]
    return sum

#########################
#
# sum causes 0.658599s
#
```

Now, we are finnally reaching the speed of c. And the code looks exactly as a c code.

Cython is not the only tool that let Python code call c code. 
But it provides a simple way to write the c code and connect them together.

Another convenient tools is numba, which compiles python codes directly at runtime. 
You even do not need to consider the data types because numba infers the data types for you. 
But that is the reason why I prefer Cython than numba.
Cython enables me to control everything, just like what I can do in c.




